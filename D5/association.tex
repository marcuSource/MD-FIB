\section{Association Rules}
\subsection{Objectives}
Association Rules are an unsupervised data mining method designed to discover interesting relationships, frequent patterns, or correlations among sets of items in large databases. 

Their most well-known use is market basket analysis (Ex: \textit{``If a customer buys A and B, is it likely that they will buy C?''}). However, we intend to use them to identify the customer profiles most likely to accept the latest marketing campaign.

To perform our association rule analysis, we have decided to use the following categorical variables from our enriched database that have the most influence on our results.

\begin{enumerate}
\item \textbf{Response}: Represents the acceptance of the last campaign. The purpose of the analysis is to find which combinations of attributes increase the probability of success ($\texttt{Response} = \texttt{Yes}$).

\item \textbf{CustomerSegment}: This variable serves as a summary of the client's overall behavior (Cluster 1, 2, or 3). This inclusion allows us to verify whether success or failure is concentrated within a predefined segment (Low, Mid, High Value). 

\item \textbf{IncomeSegment}: This variable is the principal interpreter of PC1 (Value). It differentiates clients based on their economic capacity (Low, Medium, High). This variable is quite important to consider as it is the most discriminating factor in the dataset.

\item \textbf{PreferredChannel}: In the PCA, we observed that the channel defines the behavior; that is, the "Discount/Web" client is very different from the traditional "Store/Catalog" client. For this reason, we can use it to determine where to launch the campaign. 

\item \textbf{PreferredProductCategory}: This allows linking the campaign's success to specific preferences, such as meat or wine. 

\item \textbf{MaritalSts}: This variable provides the social context. Although many profiles were similar, we were able to find, for instance, that the "\textit{Widow}" status was unexpectedly associated with high-income and traditional clients. 

\item \textbf{Education}: Actúa como un indicador indirecto del nivel de ingresos y sofisticación. Vuestro análisis mostró que el nivel "Básico" estaba fuertemente ligado al segmento de bajo valor, lo cual ayuda a las reglas a filtrar quién no va a comprar.

Además, hemos decidido discretizar las siguientes:

\item \textbf{Age}: Esta variable es representante del PC3 (Madurez). Al discretizarla, podemos detectar si la campaña funciona mejor en segmentos generacionales específicos. Para discretizarla hemos decidido separar las edades en 3 segmentos : EXPLICAR!!!!!!!

\item \textbf{WineExp}: Dado que el vino es el producto estrella, la podemos utilizar para distinguir entre quién gasta "poco" y quién gasta "mucho". En resumen, es vital para encontrar nichos de rentabilidad.

EXPLICAR COMO SE HA DISCRETIZADO    
\item \textbf{Teenhome}: Fue la variable más influyente del PC2. Su presencia cambia radicalmente la forma de comprar: \textbf{fuerza la búsqueda de ofertas} y el uso de la web, siendo clave para predecir el comportamiento digital. Es fundamental tratarla como factor para ver reglas como "Si tiene adolescentes -> Busca ofertas". 
EXPLICAR?
\item \textbf{Kidhome}: En nuestro análisis inicial pudimos confirmar que tener niños pequeños reduce el presupuesto para lujos (como el vino o el oro). Es fundamental para explicar por qué ciertos clientes, aunque quieran, no gastan mucho. 
eXPLICAR?
\end{enumerate}
En resumen, esta selección de variables cubre las tres dimensiones halladas en el PCA:

\begin{enumerate}
    \item \textbf{Dimensión Valor:} Cubierta por \verb|IncomeSegment|, \verb|WineExp| y \verb|CustomerSegment|.
    \item \textbf{Dimensión Ciclo de Vida:} Cubierta por \verb|Teenhome|, \verb|Kidhome| y \verb|PreferredChannel|.
    \item \textbf{Dimensión Demográfica:} Cubierta por \verb|Age|, \verb|Education| y \verb|MaritalSts|.
\end{enumerate}
Al utilizar estas variables específicas, garantizamos que las reglas generadas tengan una explicación de negocio coherente con el análisis previo.

\subsection{Choosing algorithm: Apriori}
Antes de obtener las reglas de asociación, hemos debatido sobre què algoritmo  utilizar para encontrarlas. 

Dado que los clientes que aceptan una campaña son minoría en nuestra base de datos, nuestro objetivo es encontrar pequeños nichos de clientes con las mismas características que sean propensos a aceptar la última campaña de marketing. Por este motivo hemos decidido utilizar el algoritmo \textbf{Apriori}, ya que está diseñado para generar y evaluar reglas de asociación basándose en métricas de dirección como la \textit{Confianza} y el \textit{Lift}.

Por otra parte, descartamos el uso del algoritmo Eclat ya que este se especializa en la detección de conjuntos frecuentes mediante intersecciones verticales, por lo que no se ajusta a nuestros intereses. 

\subsection{Evaluation}
Una vez escogido algoritmo, tenemos que ajustar el soporte y la confianza para poder encontrar las reglas que más nos interesan.

Al buscar grupos específicos de clientes hemos definido el Soporte a 1\% (20 personas aprox).

Por otra parte, dado que el porccentage de gente que acepta la campaña (Response = Yes) es de un 15\%, cualquier Confianza superior a 15\% ya serà mejor que el promedio. Por esta razón, hemos decidido establecer la confianza al \textbf{30\%}, porque \textbf{duplicaria} la eficiencia actual de la campaña. 

Inicialmente ejecutamos esta línea en R.
\begin{lstlisting}
rulesApriori <- apriori(db_transaciones, 
                parameter = list(support = 0.01, 
                                confidence = 0.25, 
                                minlen = 2))
summary(rulesApriori)
\end{lstlisting}
La salida resultante fue:

\includegraphics[width=1.0\textwidth]{Images/AprioriOutput0.png}

A partir de esta observamos que se encontraron un total de 174.027 reglas. Esta cantidad de reglas es demasiado compleja como para analizarla correctamente. Por otra parte, el lift medio (1.4575) indica que el promedio de las reglas apenas mejora un resultado al azar.

Sin embargo, cabe destacar que el lift máximo (6.799) indica que dentro de esas 170.000 reglas hay "pepitas de oro" muy valiosas, pero están escondidas entre miles de reglas irrelevantes.

Al tener tanto exceso de ruido y una complejidad difícil de gestionar, hemos decidido apuntar directamente a los que han aceptado la campaña con la siguiente línea de codigo:

\begin{lstlisting}
rulesApriori <- apriori(dtrans, 
                parameter = list(supp = 0.01,
                                 conf = 0.3,
                                 minlen = 2),
                appearance = list(rhs = "Response=Yes", default="lhs"))
summary(rulesApriori)
\end{lstlisting}

De esta forma obtenemos estos mejores resultados:

\includegraphics[width=1.0\textwidth]{Images/AprioriOutput1.png}

Tras este segundo análisis, hemos reducido las reglas de 174.027 a 702 lo cual es lo suficientemente amplio para encontrar varios perfiles distintos de clientes.

Al apuntar directamente a los resultados positivos, vemos que el lift medio (2.615) mejora el resultado inicial ya que las reglas mejoran más del doble.

Por otra parte el lift máxmimo (4.408) a pesar de ser menor que el anterior, sigue siendo un buen resultado.

Si nos fijamos en el valor de la confianza, vemos que va de 30-67\%. Aunque a primera vista no sea un resultado tan alto, recordemos que el porcentaje de éxito de la variable Response es del 15\% por lo que, en el peor de los casos, estamos encontrando nichos que duplican ese porcentaje.

Por último, el sporte y el count nos pueden ayudar a determinar el tamaño de nuestro nicho. Al oscilar entre 0.01 y 0.07 vemos que el grupo de clientes que nos interesa es de 21-150 personas.

Sin embargo, cabe destacar que el lift máximo (6.799) indica que dentro de esas 170.000 reglas hay "pepitas de oro" muy valiosas, pero están escondidas entre miles de reglas irrelevantes.

Visualmente podemos ver estas relaciones co ......

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{Images/LiftXSuport1.png}
    \hfill
    \includegraphics[width=0.48\textwidth]{Images/LiftXSuport2.png}
    \caption{Scatter plot NOMBRE PROVISIONAL}
\end{figure}

Si nos fijamos en el order, vemos que las más repetidas son las de orden 4-8

\includegraphics[width=1.0\textwidth]{Images/ParallelCoordinates.png}
Para poder ver las 
Al observarlas con el grafico de coordenadas paralelas vemos que ...

De esta manera hemos descubierto que las reglas de asociacion que nos permiten mejorar nuestras futuras campañas de marketing son:

\begin{enumerate}
    \item \textbf{Rule 1:}
    \item \textbf{Rule 2:}
    \item \textbf{Rule 3:}
    \item \textbf{Rule 4:}
    \item \textbf{Rule 5:}
    \item \textbf{Rule 6:}
    ...
\end{enumerate}
Notas: 
- REVISAR ACCURACYY!!!!!!!!!!!!!
- Ver parallel coordinates de 5, 10 y 20 y escoger mejor
